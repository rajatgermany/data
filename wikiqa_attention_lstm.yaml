data-module: experiment.qa.data.wikiqa.wikiqa
model-module: experiment.qa_hinge.model.lp_paper.attention_lstm
training-module: experiment.qa_hinge.train.training
evaluation-module: experiment.qa_pairwise.evaluation.evaluation

output: '/home/rajatuiet/aspect-based/output'
logger:
  level: DEBUG
  path: logs/wikiqa/attention-lstm/basicEvaluation/all_questions/e2e/answer_to_answer_pronoun.txt

global:
  question_length: 56
  answer_length: 200
  embedding_size: 300

data:
  lowercased: true
  map_oov: true
  map_numbers: false
  embeddings_path: /home/rjain/rajat/aspect-based/experiment/qa/data/glove.840B.300d.txt
  wikiqa: /home/rjain/rajat/aspect-based/experiment/qa/data/wikiqa/V2

model:
  lstm_cell_size: 141
  window_size: 2
  trainable_embeddings: true
  margin: 0.2

training:
  n_train_answers: 50
  save_folder: checkpoints/wikiqa-attention-lstm
  remove_save_folder_on_start: false
  epochs: 100
  early_stopping_patience: 10
  dropout: 0.2 #0.0

  optimizer: adam
  initial_learning_rate: 0.0004 #0.001
  dynamic_learning_rate: false

  scorer: accuracy
  
  optimizer: adam
  initial_learning_rate: 0.0001 #0.001
  dynamic_learning_rate: false

  scorer: accuracy
  scorer_print:
    - map
    - mrr

  batchsize: 20
  batchsize_valid: 500

evaluation:
  skip: false

split_index: 4
data_type: 'insuranceqa'
only_referent_questions: false
add_coref: true

